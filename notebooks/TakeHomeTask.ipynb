{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN5a3gvqM-rk",
        "outputId": "99136bf4-0a40-4921-ec86-a8ba08d705a9"
      },
      "outputs": [],
      "source": [
        "!wget https://www-cs-toronto-edu.translate.goog/~kriz/cifar-10-python.tar.gz?_x_tr_sl=en&_x_tr_tl=es&_x_tr_hl=es&_x_tr_pto=tcb -O cifar-10-python.tar.gz\n",
        "!tar -xvzf cifar-10-python.tar.gz?_x_tr_sl=en\n",
        "\n",
        "!pip install loguru\n",
        "!pip install plotly\n",
        "!pip install open_clip_torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJBz6CTD8dSh",
        "outputId": "640fa344-550a-45d6-9fff-0e5bbc145179"
      },
      "outputs": [],
      "source": [
        "import open_clip\n",
        "\n",
        "model, _, preprocess = open_clip.create_model_and_transforms(\n",
        "    \"ViT-B-32\", pretrained=\"laion2b_s34b_b79k\"\n",
        ")\n",
        "model.eval()  # model in train mode by default, impacts some models with BatchNorm or stochastic depth active\n",
        "model = model.to(\"cuda\")\n",
        "\n",
        "tokenizer = open_clip.get_tokenizer(\"ViT-B-32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaL6GE6Cyhuc"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH7T0CfONomX",
        "outputId": "c2c23fb4-3d80-4b23-afcb-d524cfc9a498"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from loguru import logger\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "def unpickle(path):\n",
        "    logger.info(f\"File loaded: {path}\")\n",
        "    with open(path, \"rb\") as fo:\n",
        "        loaded_dict = pickle.load(fo, encoding=\"bytes\")\n",
        "    logger.info(f\"Loaded dict batch label: {loaded_dict[b'batch_label']}\")\n",
        "\n",
        "    return loaded_dict\n",
        "\n",
        "\n",
        "class CIFAR10Dataset(Dataset):\n",
        "    def __init__(self, paths, n_images: int | None = None):\n",
        "        self.labels = []\n",
        "        self.images = None\n",
        "\n",
        "        for path in paths:\n",
        "            data_batch = unpickle(path)\n",
        "\n",
        "            self.labels += data_batch[b\"labels\"]\n",
        "            if self.images is None:\n",
        "                self.images = data_batch[b\"data\"]\n",
        "            else:\n",
        "                self.images = np.concat([self.images, data_batch[b\"data\"]])\n",
        "\n",
        "        if n_images != None:\n",
        "            self.labels = self.labels[0:n_images]\n",
        "            self.images = self.images[0:n_images]\n",
        "\n",
        "        logger.info(\"Dataset info:\")\n",
        "        logger.info(f\"\\tShape: {self.images.shape}\")\n",
        "        logger.info(f\"\\tSize: {self.images.nbytes / 10e6} MB\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        preprocessed_image = preprocess(\n",
        "            Image.fromarray(image.reshape(3, 32, 32).transpose(1, 2, 0))\n",
        "        )\n",
        "        return preprocessed_image, label\n",
        "\n",
        "\n",
        "train_dataset = CIFAR10Dataset(\n",
        "    [\n",
        "        \"cifar-10-batches-py/data_batch_1\",\n",
        "        \"cifar-10-batches-py/data_batch_2\",\n",
        "        \"cifar-10-batches-py/data_batch_3\",\n",
        "        \"cifar-10-batches-py/data_batch_4\",\n",
        "        \"cifar-10-batches-py/data_batch_5\",\n",
        "    ],\n",
        "    1000,\n",
        ")\n",
        "\n",
        "test_dataset = CIFAR10Dataset([\"cifar-10-batches-py/test_batch\"], n_images=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8V1oT9Q8ucE"
      },
      "outputs": [],
      "source": [
        "with open(\"cifar-10-batches-py/batches.meta\", \"rb\") as fo:\n",
        "    meta = pickle.load(fo, encoding=\"bytes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SKeoLXEnOCgh",
        "outputId": "f059425b-8e84-4fba-f1d3-ace101716cd1"
      },
      "outputs": [],
      "source": [
        "def plot_example(dataset: dict, index: int):\n",
        "    img, label = dataset[index]\n",
        "    px.imshow(\n",
        "        img.permute(1, 2, 0) * 128,\n",
        "        title=f\"Class {label} - {meta[b'label_names'][label]}\",\n",
        "        height=400,\n",
        "    ).show()\n",
        "\n",
        "\n",
        "plot_example(test_dataset, 1)\n",
        "plot_example(test_dataset, 2)\n",
        "plot_example(test_dataset, 3)\n",
        "plot_example(test_dataset, 4)\n",
        "plot_example(test_dataset, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbJXGlfbTLPO"
      },
      "outputs": [],
      "source": [
        "import open_clip\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def eval_clip(\n",
        "    dataset: CIFAR10Dataset, classes: list[str], batch_size: int, shuffle: bool = False\n",
        ") -> list[int]:\n",
        "    logger.info(\"Tokenizing classes\")\n",
        "    tokenized_classes = tokenizer(classes).to(\"cuda\")\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    logger.info(\"Generating DataLoader\")\n",
        "    dataloader = DataLoader(test_dataset, batch_size=128, shuffle=shuffle)\n",
        "\n",
        "    logger.info(\"Starting evaluation\")\n",
        "    for batch_idx, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(\"cuda\"), y.to(\"cuda\")\n",
        "        logger.info(f\"\\tProcessing batch {batch_idx}\")\n",
        "        with torch.no_grad(), torch.autocast(\"cuda\"):\n",
        "            image_features = model.encode_image(X)\n",
        "            text_features = model.encode_text(tokenized_classes)\n",
        "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "\n",
        "            pred = text_probs.argmax(dim=-1)\n",
        "            logger.info(f\"\\tBatch accuracy: {accuracy_score(y.cpu(), pred.cpu())}\")\n",
        "\n",
        "            y_pred += pred.cpu().tolist()\n",
        "            y_true += y.cpu().tolist()\n",
        "\n",
        "    logger.info(\"Classification Report:\")\n",
        "    logger.info(\n",
        "        \"\\n\"\n",
        "        + classification_report(\n",
        "            y_true, y_pred, labels=range(len(classes)), target_names=classes\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMUmdW3ZX1dK",
        "outputId": "b000187c-43f1-4284-c192-10c98c1a8bb3"
      },
      "outputs": [],
      "source": [
        "classes = [x.decode(\"utf-8\") for x in meta[b\"label_names\"]]\n",
        "logger.info(f\"Classes: {classes}\")\n",
        "\n",
        "y_pred = eval_clip(test_dataset, classes, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNVCybAdhaEs",
        "outputId": "69699919-d76c-407d-d32b-d6ebd3ad583f"
      },
      "outputs": [],
      "source": [
        "prompted_classes = [\n",
        "    \"a photo of an airplane, which is a vehicle\",\n",
        "    \"a photo of an automobile, which is a vehicle\",\n",
        "    \"a photo of a bird, which is an animal\",\n",
        "    \"a photo of a cat, which is an animal\",\n",
        "    \"a photo of a deer, which is an animal\",\n",
        "    \"a photo of a dog, which is an animal\",\n",
        "    \"a photo of a frog, which is an animal\",\n",
        "    \"a photo of a horse, which is an animal\",\n",
        "    \"a photo of a ship, which is a vehicle\",\n",
        "    \"a photo of a truck which is a vehicle\",\n",
        "]\n",
        "\n",
        "logger.info(f\"Classes: {prompted_classes}\")\n",
        "y_pred = eval_clip(test_dataset, prompted_classes, 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miwlTi-8yff-"
      },
      "source": [
        "## Part 2: Linear Probing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7AssMtBM27B"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 512\n",
        "patience = 3\n",
        "device = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOL1sx-Hx1qA"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class LinearProbeModel(nn.Module):\n",
        "    def __init__(self, input_dim: int, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.linear_layer = nn.Linear(input_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # assume [batch, feature_dim]\n",
        "        return self.linear_layer(x)\n",
        "\n",
        "\n",
        "linear_probe_model = LinearProbeModel(input_dim=512, num_classes=10).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2I48UJbYzOd9",
        "outputId": "dd5f580a-7fc7-4151-899c-2431b160784e"
      },
      "outputs": [],
      "source": [
        "import open_clip\n",
        "\n",
        "y_pred = []\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(linear_probe_model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "train_dataset = CIFAR10Dataset(\n",
        "    [\n",
        "        \"cifar-10-batches-py/data_batch_1\",\n",
        "        \"cifar-10-batches-py/data_batch_2\",\n",
        "        \"cifar-10-batches-py/data_batch_3\",\n",
        "        \"cifar-10-batches-py/data_batch_4\",\n",
        "        \"cifar-10-batches-py/data_batch_5\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "test_dataset = CIFAR10Dataset([\"cifar-10-batches-py/test_batch\"])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # training\n",
        "    for batch_idx, (X, y) in enumerate(train_dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        with torch.no_grad(), torch.autocast(\"cuda\"):\n",
        "            image_features = model.encode_image(X)\n",
        "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        linear_probe_model.train()\n",
        "        with torch.autocast(\"cuda\"):\n",
        "            logits = linear_probe_model(image_features)\n",
        "            loss = loss_fn(logits, y)\n",
        "\n",
        "            logger.info(\n",
        "                f\"[Training] Epoch {epoch + 1} | Batch {batch_idx + 1} | \"\n",
        "                f\"Loss = {round(loss.item(), 4)}\"\n",
        "            )\n",
        "\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "    logger.info(\"Evaluating in test_dataset\")\n",
        "\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    linear_probe_model.eval()\n",
        "    for batch_idx, (X, y) in enumerate(test_dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        with torch.no_grad(), torch.autocast(\"cuda\"):\n",
        "            image_features = model.encode_image(X)\n",
        "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "            image_features = image_features.float()\n",
        "\n",
        "            logits = linear_probe_model(image_features)\n",
        "            pred = logits.argmax(dim=-1)\n",
        "\n",
        "            y_pred += pred.cpu().tolist()\n",
        "            y_true += y.cpu().tolist()\n",
        "            logger.info(\n",
        "                f\"[Test] Epoch {epoch + 1} | Batch {batch_idx + 1} \"\n",
        "                f\"| accuracy = {accuracy_score(y.cpu().tolist(), pred.cpu().tolist())}\"\n",
        "            )\n",
        "\n",
        "    logger.info(f\"[Test] Epoch {epoch + 1} accuracy: {accuracy_score(y_true, y_pred)}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
